{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Algon-33/EHanson/blob/main/FineTune%20Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages\n"
      ],
      "metadata": {
        "id": "4h4r4gWXiBO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WARNING!\n",
        "Ah god, apparently OpenAI doesn't like sharing your API key on a public repo, so they said the key I entered below has been deprecated. You need to use a new key to access the model.\n"
      ],
      "metadata": {
        "id": "F21CkEROi8gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ENTER OPENAI KEY THAT I GENERATED WHILST SETTING ORGANIZATION  =  FLEETING\n",
        "%env OPENAI_API_KEY= None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSz8O5KX_YmA",
        "outputId": "28564483-992b-4207-dc07-cf4c1e268f99"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtfE-ORx_tIG",
        "outputId": "1087cc8d-3071-4956-d136-945fc217aac8"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.7/dist-packages (from openai) (1.2.0.62)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chronological\n",
            "  Downloading chronological-0.1.1-py3-none-any.whl (6.0 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openai in /usr/local/lib/python3.7/dist-packages (from chronological) (0.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai->chronological) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai->chronological) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai->chronological) (4.1.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai->chronological) (3.0.10)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai->chronological) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai->chronological) (2.23.0)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.7/dist-packages (from openai->chronological) (1.2.0.62)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai->chronological) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai->chronological) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai->chronological) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai->chronological) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai->chronological) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai->chronological) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai->chronological) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai->chronological) (1.24.3)\n",
            "Installing collected packages: python-dotenv, loguru, chronological\n",
            "Successfully installed chronological-0.1.1 loguru-0.6.0 python-dotenv-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n"
      ],
      "metadata": {
        "id": "zpkJeP9PPPg_"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data and Fine Tune"
      ],
      "metadata": {
        "id": "LkMuuctFiL8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OPn-LB3giX8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DOWNLOAD TRAINING AND VALIDATION SETS\n",
        "#FOR SOME STUPID REASON, ADDING THE FILES TO COLAB THIS WAY DOESN'T WORK. I HAD TO MOUNT MY DRIVE AND \n",
        "#THEN UPLOAD THE FILES TO GOOGLE DRIVE, THEN MOVE IT FROM THE DRIVE/MYDRIVE TO /CONTENT\n",
        "#!wget https://raw.githubusercontent.com/Algon-33/EHanson/main/training.jsonl\n",
        "#!wget https://raw.githubusercontent.com/Algon-33/EHanson/main/validation.jsonl\n",
        "!wget https://raw.githubusercontent.com/Algon-33/EHanson/main/shortened_training.jsonl\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Algon-33/EHanson/main/shortened_validation.jsonl\n"
      ],
      "metadata": {
        "id": "Zj8dr41Aiai8",
        "outputId": "c2f4f169-221c-485f-feac-8f483a2a57d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 15:54:11--  https://raw.githubusercontent.com/Algon-33/EHanson/main/shortened_training.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 616116 (602K) [text/plain]\n",
            "Saving to: ‘shortened_training.jsonl’\n",
            "\n",
            "\rshortened_training.   0%[                    ]       0  --.-KB/s               \rshortened_training. 100%[===================>] 601.68K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-11-01 15:54:11 (115 MB/s) - ‘shortened_training.jsonl’ saved [616116/616116]\n",
            "\n",
            "--2022-11-01 15:54:11--  https://raw.githubusercontent.com/Algon-33/EHanson/main/shortened_validation.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143367 (140K) [text/plain]\n",
            "Saving to: ‘shortened_validation.jsonl.1’\n",
            "\n",
            "shortened_validatio 100%[===================>] 140.01K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-11-01 15:54:11 (42.3 MB/s) - ‘shortened_validation.jsonl.1’ saved [143367/143367]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(name_jsonl):\n",
        "  with open(name_jsonl, \"r\", encoding = \"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "  f.close()\n",
        "  return list(map(lambda x: json.loads(x), lines))\n",
        "\n",
        "def print_len_dataset(name_jsonl):\n",
        "  print(name_jsonl + \" has length \" + str(len(get_dataset(name_jsonl)))+\"\\n\")"
      ],
      "metadata": {
        "id": "JFmwSON5NnIl"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shortened_training = get_dataset(\"shortened_training.jsonl\")\n",
        "shortened_validation = get_dataset(\"shortened_validation.jsonl\")\n",
        "\n",
        "print_len_dataset(\"shortened_training.jsonl\")\n",
        "print_len_dataset(\"shortened_validation.jsonl\")\n"
      ],
      "metadata": {
        "id": "-Yg8k7L2OG4S",
        "outputId": "3ea6dd28-0493-4509-8690-30adc2863ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shortened_training.jsonl has length 407\n",
            "\n",
            "shortened_validation.jsonl has length 102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_dataset(\"shortened_training.jsonl\")[-1];"
      ],
      "metadata": {
        "id": "-3FHNohLxtZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHECK TRAINING AND VALIDATION SETS ARE IN THE RIGHT FORMAT\n",
        "!openai tools fine_tunes.prepare_data -f shortened_training.jsonl\n",
        "!openai tools fine_tunes.prepare_data -f shortened_validation.jsonl"
      ],
      "metadata": {
        "id": "0dudLpDUNkIH",
        "outputId": "46c050b6-0957-4e95-f8c0-3b6a25674a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 407 prompt-completion pairs\n",
            "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
            "- All completions end with suffix `\\n\\n@@@\\n\\n`\n",
            "\n",
            "No remediations found.\n",
            "\n",
            "You can use your file for fine-tuning:\n",
            "> openai api fine_tunes.create -t \"shortened_training.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\\n@@@\\n\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 8.03 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
            "Analyzing...\n",
            "\n",
            "- Your file contains 102 prompt-completion pairs\n",
            "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
            "- All completions end with suffix `\\n\\n@@@\\n\\n`\n",
            "\n",
            "No remediations found.\n",
            "\n",
            "You can use your file for fine-tuning:\n",
            "> openai api fine_tunes.create -t \"shortened_validation.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\\n@@@\\n\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 3.84 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#REUSING THE MODEL I ALREADY TRAINED ON VALIDATION.JSONL.\n",
        "#NOW TRAINING IT ON TRAINING SET WITH A NEW VALIDATION SET TO ACTUALLY USE AS VALIDATION \n",
        "#!openai api fine_tunes.create -m davinci:ft-fleeting-2022-10-31-00-23-58 -t \"shortened_training.jsonl\" -v \"shortened_validation.jsonl\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjmpNRh4AR4F",
        "outputId": "f5dd4147-4e9f-4a80-8019-4f7570f9831a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'shortened_training.jsonl', purpose 'fine-tune' and size 616116 bytes\n",
            "file-U0c8lOcD0nFDwmYqzKyZAFAH\n",
            "file-fvFMCIvoRkydGpXEi7riTElC\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 616k/616k [00:00<00:00, 933Mit/s]\n",
            "Uploaded file from shortened_training.jsonl: file-0Ps6PrHkUKO043DyxNU2LngZ\n",
            "Upload progress: 100% 143k/143k [00:00<00:00, 261Mit/s]\n",
            "Uploaded file from shortened_validation.jsonl: file-MfP0vlLTvJlpRunJ9APuupU8\n",
            "Created fine-tune: ft-EFfxjdAae7tGy7fc5iCYBk4R\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2022-11-01 15:59:27] Created fine-tune: ft-EFfxjdAae7tGy7fc5iCYBk4R\n",
            "[2022-11-01 15:59:38] Fine-tune costs $15.22\n",
            "[2022-11-01 15:59:38] Fine-tune enqueued. Queue number: 14\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-EFfxjdAae7tGy7fc5iCYBk4R\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#RUN THIS TO RESTART FINETUNE STREAM\n",
        "!openai api fine_tunes.follow -i ft-EFfxjdAae7tGy7fc5iCYBk4R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhfspWYYP1w4",
        "outputId": "224366f6-2b8e-4761-97e6-2bae009b1568"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-11-01 15:59:27] Created fine-tune: ft-EFfxjdAae7tGy7fc5iCYBk4R\n",
            "[2022-11-01 15:59:38] Fine-tune costs $15.22\n",
            "[2022-11-01 15:59:38] Fine-tune enqueued. Queue number: 14\n",
            "[2022-11-01 16:16:40] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-11-01 16:17:20] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-11-01 16:22:10] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-11-01 16:23:21] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-11-01 16:30:34] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-11-01 16:30:36] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-11-01 16:32:47] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-11-01 16:32:48] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-11-01 16:32:49] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-11-01 16:54:23] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-11-01 16:58:23] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-11-01 16:59:46] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-11-01 17:16:02] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-01 17:29:47] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-01 17:30:40] Fine-tune started\n",
            "[2022-11-01 17:37:14] Completed epoch 1/4\n",
            "[2022-11-01 17:40:45] Completed epoch 2/4\n",
            "[2022-11-01 17:44:16] Completed epoch 3/4\n",
            "[2022-11-01 17:47:45] Completed epoch 4/4\n",
            "[2022-11-01 18:06:56] Uploaded model: davinci:ft-fleeting-2022-11-01-18-06-55\n",
            "[2022-11-01 18:06:58] Uploaded result file: file-i3M8HnleiH2lC3jKitx9zxex\n",
            "[2022-11-01 18:06:58] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-fleeting-2022-11-01-18-06-55 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample From Model"
      ],
      "metadata": {
        "id": "RHOy_dMfic35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HERE IS A COMPLETION I TRIED GENERATING FROM A DATE, TITLE PAIR. \n",
        "#NOTE THE \\n\\n###\\n\\n characters. They serve as an end-prompt token to the model\n",
        "!openai api completions.create -m davinci:ft-fleeting-2022-10-31-00-23-58  -p  \"\tDate: August 13, 2022 10:10 pm \\n Title: Is Nothing Sacred? \\n \\\" “is nothing sacred?” is spoken used to express shock when something you think is valuable or important is being changed or harmed  \\\" \\n Human groups often unite via agreeing on what to treat as “sacred”. While we don’t all agree on what is how sacred, almost all of us treat some things as pretty sacred way. Sacred things are especially valuable, sharply distinguished, and idealized, so they have less decay, messiness, inhomogeneities, or internal conflicts. \\n  Alas, sacredness seems pretty fragile. If sacred things are too expensive to afford, or take way too much time, or create externalities on others too great, we just cut back on our sacred things. If a religious ritual becomes expensive or inconvenient, we just get a new ritual or reinterpret our old ritual.\\n Sacredness seems to be especially fragile when people move around a lot. For example, for millennia poverty limited folks to toil in the same simple place. But lately, human groups have been more mobile, matching abstract ideas related to modern \\n\\n###\\n\\n\" --stop \"\\n\\n@@@\\n\\n\" "
      ],
      "metadata": {
        "id": "1dW0ofYBLRRd",
        "outputId": "2d80a774-601c-43ce-9118-d4e76a96d09e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tDate: August 13, 2022 10:10 pm \\n Title: Is Nothing Sacred? \\n \" “is nothing sacred?” is spoken used to express shock when something you think is valuable or important is being changed or harmed  \" \\n Human groups often unite via agreeing on what to treat as “sacred”. While we don’t all agree on what is how sacred, almost all of us treat some things as pretty sacred way. Sacred things are especially valuable, sharply distinguished, and idealized, so they have less decay, messiness, inhomogeneities, or internal conflicts. \\n  Alas, sacredness seems pretty fragile. If sacred things are too expensive to afford, or take way too much time, or create externalities on others too great, we just cut back on our sacred things. If a religious ritual becomes expensive or inconvenient, we just get a new ritual or reinterpret our old ritual.\\n Sacredness seems to be especially fragile when people move around a lot. For example, for millennia poverty limited folks to toil in the same simple place. But lately, human groups have been more mobile, matching abstract ideas related to modern \\n\\n###\\n\\nAh, I see it now. That quote is from an  article  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api completions.create -m davinci:ft-fleeting-2022-11-01-18-06-55 -p \"\tDate: August 13, 2022 10:10 pm \\n Title: Is Nothing Sacred? \\n \\\" “is nothing sacred?” is spoken used to express shock when something you think is valuable or important is being changed or harmed  \\\" \\n Human groups often unite via agreeing on what to treat as “sacred”. While we don’t all agree on what is how sacred, almost all of us treat some things as pretty sacred way. Sacred things are especially valuable, sharply distinguished, and idealized, so they have less decay, messiness, inhomogeneities, or internal conflicts. \\n  Alas, sacredness seems pretty fragile. If sacred things are too expensive to afford, or take way too much time, or create externalities on others too great, we just cut back on our sacred things. If a religious ritual becomes expensive or inconvenient, we just get a new ritual or reinterpret our old ritual.\\n Sacredness seems to be especially fragile when people move around a lot. For example, for millennia poverty limited folks to toil in the same simple place. But lately, human groups have been more mobile, matching abstract ideas related to modern vernacular \\\"fashions\\\", who leave their simple old places at tge\" --stop \"\\n\\n@@@\\n\\n\" "
      ],
      "metadata": {
        "id": "g0h22GoW2pID",
        "outputId": "f7dde670-9973-4412-c4cc-2e0cf8ab06c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tDate: August 13, 2022 10:10 pm \\n Title: Is Nothing Sacred? \\n \" “is nothing sacred?” is spoken used to express shock when something you think is valuable or important is being changed or harmed  \" \\n Human groups often unite via agreeing on what to treat as “sacred”. While we don’t all agree on what is how sacred, almost all of us treat some things as pretty sacred way. Sacred things are especially valuable, sharply distinguished, and idealized, so they have less decay, messiness, inhomogeneities, or internal conflicts. \\n  Alas, sacredness seems pretty fragile. If sacred things are too expensive to afford, or take way too much time, or create externalities on others too great, we just cut back on our sacred things. If a religious ritual becomes expensive or inconvenient, we just get a new ritual or reinterpret our old ritual.\\n Sacredness seems to be especially fragile when people move around a lot. For example, for millennia poverty limited folks to toil in the same simple place. But lately, human groups have been more mobile, matching abstract ideas related to modern vernacular \"fashions\", who leave their simple old places \n",
            "\n",
            "at the first opportunity, seeking fashion, change, or just adventure."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xr6LeEgsB7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}